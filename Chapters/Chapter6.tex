\chapter{نتیجه‌گیری}
\pagebreak
در این پایان‌نامه، \lr{CTran}، که مدلی مبتنی بر شبکه‌ی کانولوشنی و ترنسفورمر است، برای درک زبان طبیعی ارائه شد. مدل پیشنهادی از معماری رمزنگار-رمزگشا بهره می‌برد و برای آموزش دو وظیفه‌ی تشخیص هدف و پر کردن جای خالی، از یک رمزنگار اشتراکی استفاده می‌کرد. در معماری پیشنهادی، مدل زبانی برت به عنوان تعبیه‌گر واژه‌ها استفاده شد. سپس نمایش جدیدی از کلمات با استفاده از شبکه‌ی کانولوشنی ایجاد و به جای عملیات \lr{Pooling}، از ساختار توالی ویژگی پنجره استفاده شد. برای حفظ رابطه‌ی یک به یک واژه‌های ورودی با برچسب‌های هدف، اندازه هسته‌ی ۱ در شبکه‌ی کانولوشنی در کنار سایر اندازه‌ها هسته اضافه شد. همچنین برای ادغام معنای واژه‌های همسایه در یکدیگر، اندازه هسته‌های ۱ تا ۵، به صورت ترکیبی استفاده شد. در نهایت، از پشته‌ی رمزنگار ترنسفورمر برای ایجاد تعبیه‌ی نهائی واژه‌ها بهره برده شد. در معماری \lr{CTran} برای هر وظیفه، یک رمزگشا تعریف شد.
برای وظیفه‌ی تشخیص هدف، از توجه به خود و به دنبال آن یک لایه کاملاً متصل استفاده گردید.  همچنین، رمزگشای ترنسفورمر تراز شده برای وظیفه‌ی پر کردن جای خالی معرفی و ضمن ساخت یک پشته از آن، برچسب‌های هدف تولید شدند.  در پایان، مدل پیشنهادی با مدل‌های شناخته‌شده مقایسه شد و نتایج نشان داد که مدل \lr{CTran} در وظیفه‌ی پر کردن جای خالی از مدل‌های موجود بهتر عمل می‌کند. 


در این پایان‌نامه، دو سیاست مدل زبانی به جای رمزنگار و مدل زبانی به عنوان تعبیه برای به کارگیری مدل‌های زبانی در معماری شبکه آزمایش شد و نتایج نشان داد که استفاده از مدل‌های زبانی به عنوان تعبیه‌ی کلمه، استراتژی بهتری نسبت به ترکیب آن‌ها در ساختار شبکه دارد. در مقابل، استفاده از مدل‌های زبانی به عنوان تعبیه، به معنای معرفی یک رمزنگار جدا برای شبکه و در نتیجه، معرفی پارامترهای جدید به شبکه است. این امر ذاتاً باعث ایجاد بار محاسباتی جدید می‌شود. از این رو،  تاثیر این دو استراتژی در سرعت آموزش و سرعت استنتاج، اندازی گیری شد و تاخیر اضافه‌ی ایجاد شده در شبکه گزارش گردید.


در پایان کار، مواردی هست که می‌توان در آینده آن‌ها را بررسی کرد.\\
\textbf {\ding{118}معرفی یک مکانیزم برای تزریق صریح هدف به وظیفه‌ی پر کردن جای خالی یا برعکس:} 
در این شیوه، با تزریق بردار تعبیه‌ی اهداف یا بردار توجه آن‌ها، به رمزگشای پر کردن جای خالی، مدل را به منظور انتخاب برچسب‌های صحیح راهنمایی می‌کنند. ما در این راستا، دو سیاست را برای ترکیب خروجی‌ها آزمایش کردیم؛ سیاست اول، میانگین‌گیری از ماتریس تفکر برچسب، تبدیل آن به بردار و ترکیب آن با بردار توجه تشخیص هدف، بود. سیاست دوم، الحاق خروجی تشخیص هدف با هر برچسب، قبل از لایه‌ی خطی که ابعاد آن را کاهش می‌دهد، بود. ما هیچ بهبودی پس از اعمال این دو سیاست در مدل مشاهده نکردیم؛ از این رو نتایج آن در این پایان نامه ذکر نشده است. تحقیقات آینده می‌تواند به معرفی مکانیزمی برای ترکیب بهینه‌ی این دو وظیفه با یکدیگر بپردازد.\\
\textbf {\ding{118}مدل زبانی مبتنی بر شبکه‌ی کانولوشنی و ترنسفورمر:}
در این پژوهش، مشاهده شد که استفاده از شبکه‌ی کانولوشنی با پشته‌ی رمزنگار ترنسفورمر عملکرد شبکه را بهبود می‌بخشد. این نتیجه، نوید از سودمندی این معماری می‌دهد؛ بنابراین در آینده می‌توان یک مدل زبانی مبتنی بر کانولوشن-ترنسفورمر معرفی کرد و عملکرد آن را با مدل زبانی برت سنجید.\\
\textbf {\ding{118}آزمایش معماری در سایر وظیفه‌ها:} 
همان‌طور که در فصل اول گفته شد، معماری معرفی شده برای درک زبان طبیعی، کاربرد گسترده‌ای در پردازش زبان طبیعی دارد؛ چرا که خروجی آن به شکلی است که امکان استفاده از این ساختار شبکه را در بسیاری از وظایف پردازش زبان طبیعی می‌دهد. در پژوهش‌های آینده، می‌توان عملکرد این معماری در سایر وظایف را نیز سنجید. این سنجش نیازی به تغییر ساختار معماری ندارد و مدل عیناً قابلیت جابجایی برای وظایف یاد شده در فصل اول را دارد. همچنین، با بسط دادن معماری، می توان آن را در سایر وظایفی که نامی از آن‌ها برده نشده است نیز به کار گرفت.\\
\textbf {\ding{118}بررسی دقیق‌تر مدل‌های زبانی:} 
ما در پژوهش خود، عملکرد دو مدل زبانی المو و برت را سنجیدیم. ما همچنین عملکرد مدل را با سایر مدل‌های زبانی مطرح که شامل اکس ال نت\LTRfootnote{XLNet}، روبرت\LTRfootnote{RoBert}، الکترا\LTRfootnote{Electra} هستند نیز سنجیدیم. عملکرد این مدل‌ها در مقابل برت بر روی معماری ما بهبودی نداشت؛ اما از طرفی مقایسه‌ی انجام شده عادلانه نبود. علت ناعادلانه بودن آن، آموزش برت بر روی داده‌هایی با حروف کوچک بود؛\LTRfootnote{Uncased}. متن جملات در هر دو مجموعه داده‌ی \lr{ATIS}‌ و \lr{SNIPS}، با حروف کوچک است. این درحالی است که مدل‌های زبانی روبرت، الکترا و اکس ال نت، بر روی مجموعه داده‌ی با حروف کوچک و بزرگ\LTRfootnote{Cased} آموزش داده شده‌اند. از این رو، در جدول نتایج این پایان نامه، نتایج مربوط به سه مدل زبانی یاد شده، درج نشده است. در آینده می‌توان به دو روش، مقایسه‌ی عادلانه‌ای، بین این مدل‌های زبانی برای وظیفه‌ی درک زبان طبیعی انجام داد. نخست، آموزش مدل‌های زبانی مذکور بر روی داده‌های حروف کوچک است که این مورد از نظر هزینه‌ی محاسباتی، بار سنگینی دارد. دوم، تغییر جملات مجموعه داده به حروف کوچک و بزرگ است که نیازمند نیروی کار و هزینه‌ی مادی است.